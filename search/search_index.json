{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"AIDA Data Hub Docs Documentation and user guides for services offered by     AIDA Datahub Data Science Platform <p>First login to DSP</p> <p>Logging into machine</p> Data <p>Download dataset from AIDA Nextcloud</p>"},{"location":"data/data-sharing-request/","title":"Requesting access to AIDA Data Hub dataset through REMS","text":"<p>Most datasets on the AIDA Data Hub use REMS (Resource Entitlement Management System) to manage requests for and access to datasets. This system allows you to apply for access to datasets and for handlers to review your application. Before you request access to a dataset, you must first login at https://rems.dsp.aida.scilifelab.se/</p> <p></p> <p>To login to REMS, you need to authenticate using Life Science Login. If you don't already have a user at Life Science login, please follow this guide.</p>"},{"location":"data/data-sharing-request/#using-rems","title":"Using REMS","text":"<p>Once you have authenticated using Life Science login, you will be redirected back to REMS, you will see the dataset catalogue:</p> <p></p> <p>Here you can browse all available datasets and add them to a cart. Each application still needs to be done one at a time, but the cart allows you to collect datasets of interest before beginning the application process. After you've added a dataset to the basket, you will have the option to apply for access:</p> <p></p>"},{"location":"data/data-sharing-request/#applying-for-access","title":"Applying for access","text":"<p>To apply for a dataset, click the <code>Apply</code> button. This will take you to the application form.</p> <p></p> <p>This form has multiple fields which needs to be filled in. All datasets have some form of agreement you need to accept. Often, these are in the form of PDF attachment which you need to download and review before agreeing.</p> <p>Many datasets also have mandatory fields to demonstrate that the recipient researcher is qualified to conduct ethical research using medical data. Details about the researcher are required for us to lawfully share the data. For further details, see the section Legal explanation.</p> <p>At the top right of the application form, you will find a set of available actions:</p> <ul> <li>Save as draft: Save the current state of your application without submitting it. You can continue working on it later.</li> <li>Send application: Submit the application for processing. It will appear in your list of applications.</li> <li>Delete draft: Delete the application, removing it from your list of applications.</li> <li>Copy as new application: Create a new application for the same dataset, with the same filled-in details.</li> <li>Download PDF: Download a PDF version of the application.</li> </ul> <p>Once you have filled in the application, use the Send application action to submit it for processing. A handler will manually review your application. Once the review is complete, you will receive a decision, either approval or rejection.</p>"},{"location":"data/data-sharing-request/#approved-applications","title":"Approved applications","text":"<p>If your application is approved, you will receive an email with instructions on how to access the dataset. Please note that download credentials are time-limited, so be sure to use them promptly.</p>"},{"location":"data/data-sharing-request/#rejected-applications","title":"Rejected applications","text":"<p>A rejection usually means that the handler could not, with reasonable effort, verify that the recipient researcher meets the legal requirements to receive the data (see Legal explanation). If your application is rejected due to insufficient information, you are welcome to submit a new one, but please ensure that:</p> <ul> <li>The recipient researcher holds at least a PhD in a relevant field.</li> <li>The researcher's email address is clearly associated with the stated institution.</li> <li>The researcher's profile page and other supporting links clearly demonstrate competence in conducting ethical medical research in a relevant field.</li> </ul> <p>The clearer the researcher\u2019s credentials are (e.g., an institutional email address, a detailed institutional profile page, and a publication record or position relevant to the field), the easier it will be for the handler to process the application.</p>"},{"location":"data/data-sharing-request/#the-application-listing","title":"The Application listing","text":"<p>You can see the status of your applications in REMS under the Applications menu:</p> <p></p> <p>You can continue working on your saved drafts, as well as review your submitted applications.</p>"},{"location":"data/data-sharing-request/#legal-explanation","title":"Legal explanation","text":"<p>As a policy, we require the recipient researcher to hold at least a PhD in a relevant field. This requirement has to do with the legal framework under which the data can be shared.</p> <p>This requirement is based on the legal framework governing data sharing. According to Swedish law, clinical datasets can be shared only when used for research activities conducted under the supervision of a qualified researcher, someone with the necessary scientific competence to ensure that research is carried out as described in the ethical review application and in accordance with institutional policies.</p> <p>For a more detailed discussion of the legal framework surrounding the sharing of clinical data in Sweden, please see the Legal Discussion on the AIDA Data Hub.</p>"},{"location":"data/download-dataset/","title":"Download a dataset from AIDA Nextcloud using rclone","text":""},{"location":"data/download-dataset/#step-1-setup-a-remote","title":"Step 1 - Setup a remote","text":"<pre><code>rclone config create drsk webdav url=https://nextcloud.aida.scilifelab.se/public.php/webdav vendor=nextcloud user=&lt;USERNAME&gt; pass=&lt;PASSWORD&gt;\n</code></pre> <p>Here, we have chosen the name <code>drsk</code> for the remote. You can of course choose whatever name you want. Probably use something short that doesn't contain spaces.</p> <p>Your username is the last part of the share link you got from us, i.e: <code>https://nextcloud.aida.scilifelab.se/s/USERNAME</code></p> <p>Your username could for example be something like <code>Y4gVyiVyyiF6fug</code>.</p> <p>Your password is the string of random characters you got from us separately. You will probably need to \"quote\" or 'quote' it on the command-line, as it very likely contains special characters.</p> <p>If you'd rather answer questions interactively, do this instead, and do what it says:</p> <pre><code>rclone config`\n</code></pre> <p>The exact questions may differ depending on what version rclone you have.</p>"},{"location":"data/download-dataset/#step-2-download-from-the-remote","title":"Step 2 - Download from the remote","text":"<p>Use the same name here that you chose in the previous step.</p> <pre><code>rclone copy drsk: .\n</code></pre> <p>Or if you want progress written to the terminal:</p> <pre><code>rclone copy --progress drsk: .\n</code></pre>"},{"location":"data/working-with-dicom/","title":"Working with DICOM","text":"<p>Digital Imaging and Communications in Medicine (DICOM) is the international standard to transmit, store, retrieve, print, process, and display medical imaging information. It is prevalent in radiology and is gaining traction also in pathology.</p> <p>Some datasets on the AIDA Data Hub are provided in DICOM format. In DICOM, data is provided in nested and interlinking structures, which can be nontrivial for newcomers to the field to navigate.</p> <p>For an introduction to how one can work with DICOM data, AIDA is providing a Jupyter notebook, which is publicly available through the SciLifeLab/NBIS GitHub organization:</p> <p>https://github.com/NBISweden/dicom-data-visualizer</p>"},{"location":"dsp/advanced/custom-proxy/","title":"Setting up a custom HTTP Proxy","text":"<p>By default, the Virtual Machines (VMs) on the Data Science Platform (DSP) can make HTTP requests to the outside world only by going through an inspecting proxy. To make the default configuration of DSP secure, this proxy has a strict list of allowed resources that internal machines can access. For some projects, the default is too strict, and one way of getting around it is to set up your own proxy for your VMs.</p> <p>But do note that before doing so you must verify that it follows the overall security guidelines for the current research project.</p> <p>In this guide, we will set up a different proxy on a VM using <code>privoxy</code> and tunnel HTTP requests through the connecting machine\u00b4s SSH connection.</p> <p>As a curiosity, this builds a lot on functionality offered by OpenSSH and the privoxy bits can in many cases be bypassed by referencing the SOCKS5 proxy OpenSSH provides directly, e.g. by <code>http_proxy=socsk5h://127.0.0.1:3128</code>. But while it has fairly wide support it's not universal, and adding privoxy to serve as a http proxy will help with some of those - but if you just need a quick <code>apt install</code> or similar, you can bypass that and use the socks proxy directly.</p> <p>Note that this will circumvent strict filtering and essentially allow any HTTP request from your VM to be carried out (unless you explicitly add filtering on your own machine or network).</p>"},{"location":"dsp/advanced/custom-proxy/#set-up-privoxy-on-the-vm","title":"Set up <code>privoxy</code> on the VM","text":"<p><code>privoxy</code> is a simple web proxy which is provided in the base Ubuntu repositories, this means that it will be easy to install it on Ubuntu-based VMs on DSP since the default package repositories are in our allow lists. Install it on your VM by running:</p> <pre><code>sudo apt install privoxy\n</code></pre> <p>Now we need to configure it to forward requests using SOCKS5:</p> <pre><code>echo 'forward-socks5  /  127.0.0.1:3128  .' | sudo tee -a /etc/privoxy/config\n</code></pre> <p>Restart <code>privoxy</code> to read the changes:</p> <pre><code>sudo systemctl restart privoxy\n</code></pre> <p>Now disconnect from the VM (we need to add additional configurations to the SSH client)</p> <pre><code>exit\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#configure-ssh","title":"Configure SSH","text":"<p>Above, we configured <code>privoxy</code> to forward HTTP requests to a SOCKS5 proxy on the port <code>3128</code> on the machine where it\u00b4s running (i.e. the VM). We'll now make our own connecting machine relaying the HTTP requests by telling our SSH client to listen to this port on the remote host (VM) and tunnel traffic to our connecting machine. We do this by using a \"remote forward\" connection. You can do this \"on-the-fly\" when you connect to your machine using the flag <code>-R 3128</code>, but it's more convenient to add this to your SSH config:</p> <pre><code>Host dsp-project\n  HostName [VM_FLOATING_IP]\n  User ubuntu\n  ProxyJump dsp\n  ServerAliveInterval 10\n  RemoteForward 3128 localhost:3128\n\nHost dsp\n  Hostname dsp.aida.scilifelab.se\n  User [MY_EMAIL]\n</code></pre> <p>The <code>RemoteForward 3128</code> is what sets up the reverse tunnel.</p> <p>Now when you connect to your VM over SSH (e.g. <code>ssh dsp-project</code> in config example above), SSH will forward any traffic connecting to the port 3128 on the VM to our connecting machine and carry out the HTTP requests.</p>"},{"location":"dsp/advanced/custom-proxy/#configure-remote-programs","title":"Configure remote programs","text":"<p>By default, the VM is configured to use the DSP HTTP proxy. This is set up using the environmental variables <code>HTTP_PROXY</code>, <code>HTTPS_PROXY</code>, <code>http_proxy</code> and <code>https_proxy</code>. We'll replace their values with the address of our <code>privoxy</code> instance instead. By default it listens to port 8118 for requests, so we'll set our environmental variables to this:</p> <pre><code>export http_proxy=http://127.0.0.1:8118 https_proxy=http://127.0.0.1:8118\nexport HTTP_PROXY=http://127.0.0.1:8118 HTTPS_PROXY=http://127.0.0.1:8118\n</code></pre> <p>This changes the variables for the currently running shell (so just for your current session). Once you have exported the variables, you should be able to test that the proxy works by running (in the same shell):</p> <pre><code>curl -v --proxy http://127.0.0.1:8118 https://example.com\n</code></pre> <p>Which should output an HTML document to you terminal; the HTMLlanding page of <code>example.com</code>.</p>"},{"location":"dsp/advanced/custom-proxy/#creating-alias-for-temporarily-switching-proxy","title":"Creating alias for temporarily switching proxy","text":"<p>We can add a shell alias if we want to temporarily set the environmental variables:</p> <pre><code>alias proxy='http_proxy=http://127.0.0.1:8118 https_proxy=http://127.0.0.1:8118 HTTP_PROXY=http://127.0.0.1:8118 HTTPS_PROXY=http://127.0.0.1:8118'\n</code></pre> <p>Then use it for specific commands:</p> <pre><code>proxy pip3 install numpy   # Uses proxy\npip3 install numpy         # Does not use proxy\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#making-proxy-settings-persistent","title":"Making Proxy Settings Persistent","text":"<p>The above exports of environmental variables only affect the shell you run it in, and you might want your proxy to be used throughout your account. To achieve that run the following:</p> <pre><code>cat &gt;&gt; ~/.bashrc &lt;&lt; EOF\n\n# Proxy settings\nexport http_proxy=http://127.0.0.1:8118\nexport https_proxy=http://127.0.0.1:8118\nexport HTTP_PROXY=http://127.0.0.1:8118\nexport HTTPS_PROXY=http://127.0.0.1:8118\nEOF\n</code></pre> <p>Then reload your Bash configuration:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#disabling-privoxy","title":"Disabling Privoxy","text":"<p>To remove the persistent settings from your <code>.bashrc</code>:</p> <pre><code>sed -i \\\n    -e '/^# Proxy settings$/d' \\\n    -e '/^export http_proxy=http:\\/\\/127\\.0\\.0\\.1:8118$/d' \\\n    -e '/^export https_proxy=http:\\/\\/127\\.0\\.0\\.1:8118$/d' \\\n    -e '/^export HTTP_PROXY=http:\\/\\/127\\.0\\.0\\.1:8118$/d' \\\n    -e '/^export HTTPS_PROXY=http:\\/\\/127\\.0\\.0\\.1:8118$/d' \\\n    ~/.bashrc\n</code></pre> <p>To temporarily stop Privoxy:</p> <pre><code>sudo systemctl stop privoxy\n</code></pre> <p>To disable Privoxy from starting on boot:</p> <pre><code>sudo systemctl disable privoxy\n</code></pre> <p>To completely remove Privoxy:</p> <pre><code>sudo apt remove privoxy\nsudo apt autoremove\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#configuring-apt-to-use-privoxy","title":"Configuring APT to Use Privoxy","text":"<p>While the default sources for APT are allowed in the DSP proxy, you might have added additional package repositories, in which case they will likely be blocked. You can tell APT to use privoxy instead by adding a proxy configuration file:</p> <ol> <li>Create an APT configuration file for the proxy:</li> </ol> <p><code>shell    sudo bash -c 'cat &gt; /etc/apt/apt.conf.d/80proxy &lt;&lt; EOF    Acquire::http::Proxy \"http://127.0.0.1:8118\";    Acquire::https::Proxy \"http://127.0.0.1:8118\";    EOF'</code></p> <ol> <li>Verify the configuration:</li> </ol> <p><code>shell    cat /etc/apt/apt.conf.d/80proxy</code></p> <ol> <li>Test APT with the proxy:</li> </ol> <p><code>shell    sudo apt update</code></p>"},{"location":"dsp/advanced/custom-proxy/#docker-proxy-configuration","title":"Docker Proxy Configuration","text":""},{"location":"dsp/advanced/custom-proxy/#system-wide-docker-proxy-method-1","title":"System-Wide Docker Proxy (Method 1)","text":"<ol> <li>Create or edit the Docker service configuration file:</li> </ol> <p><code>shell    sudo mkdir -p /etc/systemd/system/docker.service.d/    sudo bash -c 'cat &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt; EOF    [Service]    Environment=\"HTTP_PROXY=http://127.0.0.1:8118\"    Environment=\"HTTPS_PROXY=http://127.0.0.1:8118\"    Environment=\"NO_PROXY=localhost,127.0.0.1,::1\"    Environment=\"no_proxy=localhost,127.0.0.1,::1\"    EOF'</code></p> <ol> <li>Reload the Docker daemon configuration:</li> </ol> <p><code>shell    sudo systemctl daemon-reload    sudo systemctl restart docker</code></p> <ol> <li>Verify the Docker proxy settings:</li> </ol> <p><code>shell    sudo systemctl show --property=Environment docker</code></p>"},{"location":"dsp/advanced/custom-proxy/#docker-client-configuration-method-2","title":"Docker Client Configuration (Method 2)","text":"<p>For a user-specific Docker configuration:</p> <pre><code>mkdir -p ~/.docker\ncat &gt; ~/.docker/config.json &lt;&lt; EOF\n{\n \"proxies\":\n {\n   \"default\":\n   {\n     \"httpProxy\": \"http://127.0.0.1:8118\",\n     \"httpsProxy\": \"http://127.0.0.1:8118\",\n     \"noProxy\": \"localhost,127.0.0.1,::1\"\n   }\n }\n}\nEOF\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#docker-build-and-run-with-proxy","title":"Docker Build and Run with Proxy","text":"<p>To make your proxy available during Docker build:</p> <pre><code>docker build --network=host .\n</code></pre> <p>To run a container with host network (and thus access to your proxy):</p> <pre><code>docker run -it --rm --network host ubuntu bash\n</code></pre>"},{"location":"dsp/advanced/custom-proxy/#using-proxy-inside-docker-container","title":"Using Proxy Inside Docker Container","text":"<p>Inside the container, set up proxy configuration the same way as we've done above in this guide:</p> <pre><code># Create an alias for temporary proxy usage\nalias proxy='http_proxy=http://127.0.0.1:8118 https_proxy=http://127.0.0.1:8118 HTTP_PROXY=http://127.0.0.1:8118 HTTPS_PROXY=http://127.0.0.1:8118'\n\n# Use proxy for specific commands\nproxy pip3 install numpy   # Uses proxy\npip3 install numpy         # Does not use proxy\n\n# Or set for the entire session\nexport http_proxy=http://127.0.0.1:8118 https_proxy=http://127.0.0.1:8118\nexport HTTP_PROXY=http://127.0.0.1:8118 HTTPS_PROXY=http://127.0.0.1:8118\npip3 install numpy         # Now uses proxy\n</code></pre>"},{"location":"dsp/advanced/email/","title":"Sending emails from DSP","text":"<p>DSP supports email deliveries but to limit exfiltration possibilities, there are additional steps that need to be done to make it work.</p>"},{"location":"dsp/advanced/email/#how-it-works","title":"How it works","text":"<p>A list of allowed outgoing addresses can be registered for a secure environment. These are then possible to use as sender for outgoing emails. Emails with a different sender will be rejected.</p>"},{"location":"dsp/advanced/email/#requirements","title":"Requirements","text":"<p>To support outgoing emails, you'll need to provide</p> <ul> <li>a list of email addresses that will be used as sender addresses</li> <li>for each such outgoing address, the outgoing email details to use:</li> <li>server</li> <li>credentials (username and password) that are allowed to send emails     with the outgoing address</li> </ul> <p>We strongly encourage using separate accounts.</p>"},{"location":"dsp/advanced/email/#setup","title":"Setup","text":"<p>Currently this requires manual interaction, contact DSP support to set things up.</p>"},{"location":"dsp/advanced/email/#use","title":"Use","text":"<p>Once you have confirmation that the setup is done, you can use 10.253.254.250 as SMTP server. You do NOT need to provide authentication but we strongly encourage using encryption (TLS) for these connection, either using <code>smtps</code> or SMTP with <code>STARTTLS</code>.</p>"},{"location":"dsp/examples/gpu-iaas/","title":"GPU IaaS with custom software and data","text":"<p>Infrastructure as a Service (IaaS) provides resources that you manage yourself. It is a service for advanced customers that provides a lot of freedom to those with the skills and responsibility to handle it.</p>"},{"location":"dsp/examples/gpu-iaas/#topics","title":"Topics","text":"<p>In this example you, as a Customer lead, will go through the steps of installing software and uploading data to a GPU virtual machine you create on the AIDA Data Hub Data Science Platform (DSP) for sensitive data.</p> <p>This example assumes experience with Linux, and authority to initiate expense.</p>"},{"location":"dsp/examples/gpu-iaas/#instructions","title":"Instructions","text":""},{"location":"dsp/examples/gpu-iaas/#1-launch-a-gpu-enabled-virtual-machine","title":"1. Launch a GPU enabled virtual machine","text":"<ol> <li>Visit the DSP Horizon customer self-service portal at https://dsp.aida.scilifelab.se/</li> <li>Log in using your DSP Horizon credentials.</li> <li>Pick the correct secure environment from the project selector drop down menu    top left.</li> <li>Add your SSH public key to your project by clicking Project &gt; Compute &gt;    Key Pairs, then Import Public Key.</li> <li>Create a GPU enabled virtual machine by clicking Instances &gt; Launch instance,    and</li> <li>In Details, Instance name: Put a good name for a compute server,       like \"Jupyter demo\".</li> <li>In Source, click the up arrow icon next to an image that has Docker,       CUDA, Miniforge, Jupyter Lab and RMD.</li> <li>In Flavor, click the up arrow icon next to a flavor that has GPU.       Bigger is more expensive.</li> <li>If applicable: In Security Groups, click the up arrow icon next to       <code>incoming</code>.</li> <li>In Key Pair, verify that your key is allocated.</li> <li>Click Launch instance.</li> <li>Click Associate Floating IP &gt; IP Address &gt; pick one, fill in in next step.</li> <li>Wait for Power State to become Running.</li> </ol>"},{"location":"dsp/examples/gpu-iaas/#2-configure-your-computer-for-easy-access","title":"2. Configure your computer for easy access","text":"<p>Add to SSH-config (eg <code>~/.ssh/config</code>):</p> <pre><code>Host jupyter-demo\n  HostName [associated IP in Horizon]\n  User ubuntu\n  ProxyJump dspgateway\n  ServerAliveInterval 10\n  LocalForward 8888 localhost:8888\n  LocalForward 6006 localhost:6006\n  LocalForward 5901 localhost:5901\n\nHost dspgateway\n  HostName dsp.aida.scilifelab.se\n  User [Identity in LifeScience Login]\n</code></pre> <p>This sets up your computer to use the DSP SSH access gateway when making SSH connections to your VM. By default, DSP rejects SSH connections that are not made through the SSH access gateway.</p> <p>The configuration has two <code>Host</code> sections, one for the Virtual Machine you created (jupyter-demo) and one for the gateway (dspgateway) which you will use to \"jump\" into the secure environment.</p> <p>The <code>ProxyJump</code> command in the jupyter-demo section tells SSH that it should connect to the VM by jumping through the host <code>dspgateway</code>. SSH authentication to this gateway is done using Life Science Login, which is the default authentication method for the DSP. To log accesses and match them to the correct login account identity, your email address should be set as the <code>User</code>, replacing the placeholder [Identity in LifeScience Login].</p> <p><code>ServerAliveInterval</code> makes it easier to maintain a connection, and to detect when it has gone stale.</p> <p>The <code>LocalForwards</code> define SSH secured port forwards. They connect ports on your computer with ports on your VM in the secure environment. They allow you to work with Jupyter notebooks, TensorBoard, and VNC remote desktop running on the VM in your secure environment as if though they were running on your computer.</p>"},{"location":"dsp/examples/gpu-iaas/#3-install-software-from-public-repositories-that-are-trusted-by-the-platform","title":"3. Install software from public repositories that are trusted by the platform","text":"<p>DSP secure environments block connections by default. However, DSP provides an inspecting http proxy that enables downloading software and security updates from public repositories that are trusted by AIDA Data Hub. DSP data science images are preconfigured to make transparent use of this proxy, as demonstrated in this next step.</p> <p>Here, we clone the Jupiter notebook GitHub repository and use apt and pip to install its dependencies in a Python virtual environment. We do this inside a tmux virtual terminal so that work is kept persistent, so that running processes are not killed if connection is lost.</p> <pre><code>ssh jupyter-demo\ntmux\ngit clone https://github.com/eryl/aida-transformers-workshop-code.git\ncd aida-transformers-workshop-code\nsudo apt update\nsudo apt install python3-venv\npython3 -m venv .venv\nsource .venv/bin/activate\nexport REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt # Trust DSP CA\npip install -r requirements.txt\nsudo docker pull alpine # just for show, we don't really need Alpine nor Docker for this :)\n</code></pre> <p>Note: The restrictivity of the DSP inspecting http proxy is continually updated, to adjust to updates in public repositories that make them more or less appropriate for secure environments. For example, publicly accessible granular download counters are increasingly popular despite constituting a trivially exploitable data exfiltration method.</p>"},{"location":"dsp/examples/gpu-iaas/#4-upload-own-data","title":"4. Upload own data","text":"<ol> <li>Download demo data to your own computer, and upload it to your VM:</li> </ol> <pre><code>cd ~/Downloads\nwget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\nwget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\nrsync --progress {annotations,images}.tar.gz jupyter-demo:\n# In case you don't have rsync locally, you can use scp:\n# scp {annotations,images}.tar.gz jupyter-demo:\n</code></pre> <ol> <li>Put demo data where our Jupyter notebook expects it</li> </ol> <pre><code>ssh jupyter-demo\nmkdir -p ~/aida-transformers-workshop-code/datasets/oxfordiiipet/oxford-iiit-pet\ncd ~/aida-transformers-workshop-code/datasets/oxfordiiipet/oxford-iiit-pet\ntar xf ~/annotations.tar.gz\ntar xf ~/images.tar.gz\n</code></pre>"},{"location":"dsp/examples/gpu-iaas/#5-inspect-data-in-a-remote-desktop","title":"5. Inspect data in a remote desktop","text":"<ol> <li>Start a VNC server on your VM</li> </ol> <pre><code>sudo chown -R ubuntu:ubuntu ~/.vnc\ntightvncserver -nolisten tcp -localhost :1\n</code></pre> <p>This starts a TightVNC server on the node. We also tell it to only listen to TCP connections, and only those coming from localhost (this means other computers in the same private network can't connect to the VNC server by default).</p> <ol> <li>On your computer, point your VNC client of choice to <code>localhost:5901</code> to    connect through the SSH port forward that you set up in step 2. You can for    example use Remmina, which comes preinstalled on Ubuntu.</li> </ol> <p>Note: In the future, AIDA Data Hub will provide ways to connect to a remote desktop in a secure environment which do not require the user to have server administrator skills.</p>"},{"location":"dsp/examples/gpu-iaas/#6-use-a-jupyter-notebook-to-train-an-ai-model-and-monitor-progress-graphically","title":"6. Use a Jupyter notebook to train an AI model, and monitor progress graphically","text":"<ol> <li>Connect to your VM and start up the demo Jupyter notebook</li> </ol> <pre><code>ssh jupyter-demo\ncd ~/aida-transformers-workshop-code\nsource .venv/bin/activate\ncd notebooks\n# no pw/token, don't open a browser, only allow connections from localhost:\njupyter notebook --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.open_browser=False --NotebookApp.ip='127.0.0.1'\n</code></pre> <p>Your Jupiter notebook is now ready to use, as long as you have this SSH connection and its port forwards open.</p> <ol> <li>Using a web browser on your computer, visit    http://127.0.0.1:8888 to connect to your Jupyter    notebook through the SSH port forward that you set up in step 2. Without it, you    will not be able to connect.</li> <li>Choose transformers_for_images.ipynb</li> <li>Use Shift+Enter to run the cells manually in sequence. Edit if you like. You    are now training AI models on GPU enabled IaaS compute resources in a secure    environment on the AIDA Data Hub Data Science Platform.</li> <li>Optional: Notebook step ~23 creates a TensorBoard interface, which can be    used to monitor training progress graphically. It will initially be empty, but    as subsequent training progresses, you can use the Refresh icon in TensorBoard    interface to read and visualize current state graphically. The TensorBoard    interface uses the second SSH port forward that you set up in step 2 and cannot    connect without it.</li> </ol>"},{"location":"dsp/getting-started/basic-setup-network/","title":"Basic setup for new VMs to be able to access external resources","text":""},{"location":"dsp/getting-started/basic-setup-network/#the-short-bit","title":"The short bit","text":"<p>We offer a service at http://10.253.254.250/ which serves a script with suggested configuration. When connected to a newly deployed machine you can do the e.g. the below to configure it.</p> <pre><code>\n# Fetch the script\ncurl http://10.253.254.250/ &gt; dspconfigscript\n# Inspect and see that you don't disagree with any of the configurations\n# being done\nless dspconfigscript\n# Run the configuration script if it's fine\nbash dspconfigscript\n</code></pre>"},{"location":"dsp/getting-started/basic-setup-network/#intro","title":"Intro","text":"<p>The DSP offers an outgoing proxy giving access to a limited set of resources, but in order to use it some things need to be done in order to use it. Here we go through the most important bits that entails.</p>"},{"location":"dsp/getting-started/basic-setup-network/#certificates","title":"Certificates","text":"<p>To manage what outgoing connections should be allowed and not, the solution needs to inspect outgoing traffic, and to do that, it needs to hijack outgoing connections. To do that, we need clients to trust certificates we issue and thus require clients to import a certificate authority root we provide.</p>"},{"location":"dsp/getting-started/basic-setup-network/#importing-the-ca","title":"Importing the CA","text":"<p>To trust a new CA, we put it under <code>/usr/local/share/ca-certificates/</code> in a file with a prefix of <code>.crt</code> and run <code>update-ca-certificates</code> which makes the system at large trust the certificate.</p>"},{"location":"dsp/getting-started/basic-setup-network/#using-the-ca-for-python-virtual-environments","title":"Using the CA for python virtual environments","text":"<p>Python typically doesn't use the system CA store but rather uses the certifi package to provide the CAs (derived from those used in Mozilla).</p> <pre><code>REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\nexport REQUESTS_CA_BUNDLE\n</code></pre> <p>makes most of those packages use the system CA store instead.</p>"},{"location":"dsp/getting-started/basic-setup-network/#using-the-proxy","title":"Using the proxy","text":"<p>Most tooling will look at the environment variables <code>http_proxy</code>, <code>https_proxy</code> and <code>no_proxy</code> in various uppercase or lowercase combination. Unfortunately, behaviour isn't uniform but mostly</p> <pre><code>http_proxy=https://10.253.254.250:3130/\nhttps_proxy=https://10.253.254.250:3130/\nexport http_proxy\nexport https_proxy\n</code></pre> <p>will do the right thing.</p>"},{"location":"dsp/getting-started/basic-setup-network/#making-docker-use-the-proxy","title":"Making Docker use the proxy","text":"<p>Docker requires some special configuration to use the proxy. Providing</p> <pre><code>[Service]\nEnvironment=\"HTTP_PROXY=https://10.253.254.250:3130/\"\nEnvironment=\"HTTPS_PROXY=https://10.253.254.250:3130/\"\nEnvironment=\"no_proxy=192.168.0.0/16,10.0.0.0/8,172.16.0.0/12,192.168.*,10.*,172.1*\"\n</code></pre> <p>in <code>/etc/systemd/system/docker.service.d/http-proxy.conf</code>, reloading systemd units with <code>sudo systemctl daemon-reload</code> and restarting Docker with <code>sudo systemctl restart docker</code>.</p>"},{"location":"dsp/getting-started/basic-setup-network/#making-apt-use-the-proxy","title":"Making apt use the proxy","text":"<p><code>apt</code> also needs some configuration to use the proxy, putting</p> <pre><code>Acquire::http::Proxy \"https://10.253.254.250:3130/\";\n</code></pre> <p>in e.g. <code>/etc/apt/apt.conf.d/90proxy</code> will cause apt do use the proxy when connecting to the outside world.</p>"},{"location":"dsp/getting-started/exposing-https-services/","title":"Exposing HTTPS services in DSP to the outside","text":""},{"location":"dsp/getting-started/exposing-https-services/#introduction","title":"Introduction","text":"<p>There are use cases where you might want to expose services running in DSP to the outside world. This can be e.g. offering an interactive data explorer or accepting input data for processing and then publishing a report.</p> <p>This guide details services exposed via HTTPS. Other services may be possible to expose but that will involve another, more involved process.</p>"},{"location":"dsp/getting-started/exposing-https-services/#steps","title":"Steps","text":"<ul> <li>allocate a domain name for the service you want to expose</li> <li>wildcard names are not supported</li> <li>point the allocated name to DSP</li> <li>the recommended way to do this is to use a <code>CNAME</code> to     <code>dsp.aida.scilifelab.se</code>, but it's also possible through other means     (details subject to change for now, contact support)</li> <li>DSP will need to request a certificate for the appointed name, this will     be done through Let's Encrypt<ul> <li>for DSP to be able to do this, there can't be any restrictions denying   that (e.g <code>CAA</code> DNS records)</li> </ul> </li> <li>we also support using namespaced names, e.g.   <code>myservice.myproject.dsp.aida.scilifelab.se</code></li> <li>decide on one or more floating IP addresses that will be mapped (\"associated\")   to the VM(s) providing the service</li> <li>any special handling beyond basic up/down detection is currently not     supported (e.g. session handling is not provided)</li> <li>you will need to have the services exposed so that they are reachable from     10.253.254.248/29, i.e. at least one security group allowing the desired     traffic must be added to the instance or the corresponding port</li> <li>contact support with the allocated/desired domain name and the chosen   floating IP address(es)</li> <li>you will receive keys and certificates to use for TLS</li> </ul>"},{"location":"dsp/getting-started/exposing-https-services/#considerations","title":"Considerations","text":"<p>Once done, this will expose your service to the internet at large. It may be appropriate to take precautions, e.g. investigate if the exposed service can be isolated from other things in your secure environment.</p>"},{"location":"dsp/getting-started/first-login/","title":"First login to DSP","text":"<p>While the Data Science Platform tries not to raise to many hurdles, some things are required to make a secure system. Keeping track of who is using it is one such basic thing.</p> <p>When you go to the DSP login page you'll be greeted by a simple screen where you today only have the choice of authenticating with Life Science Login.</p> <p>.</p> <p>If you have not already registered with Life Science login, please follow this guide to do so.</p>"},{"location":"dsp/getting-started/first-login/#back-at-dsp","title":"Back at DSP","text":"<p>Once you have authenticated properly, on the first time you return, you will not be let into DSP as your account needs to be assigned membership details. Instead you will receive the message \"Login failed: You are not authorized for any projects or domains.\"</p> <p></p> <p>Once your account has been adjusted to allow log in, the next time you return you will be let into Horizon.</p> <p></p>"},{"location":"dsp/getting-started/life-science-login/","title":"Life Science federation login","text":"<p>AIDA Data Hub uses the Life Science federated login, a services operated by the European Life Science Research Infrastructures to greatly simplify authentication.</p> <p>When you select to login to our services, you will be taken to the Life Science Login federated authentication, and will be greeted by a screen where you can choose between different services, or type the name of your home organisation to authenticate there if they are available (will likely be the case for academia).</p> <p></p> <p>If your organisation is not available, there are other common services that can be used for authentication (e.g. ORCID, GitHub, LinkedIn, Google, Apple), or if you don't want to or are able to use one of these, you can use \"LifeScience Hostel\" instead which allows signing up at LS Login directly.</p>"},{"location":"dsp/getting-started/life-science-login/#using-your-home-organisation-email","title":"Using your home organisation email","text":"<p>If you use one of these other services, we recommend changing your profile email to the one from your home organisation. This can be done on the LS Login User Profile site; look for \"Preferred mail\" and click the pen to update the mail (note that the new email must be verified which may take some time).</p> <p></p>"},{"location":"dsp/getting-started/life-science-login/#multifactor-authentication","title":"Multifactor authentication","text":"<p>Once logged in, you would normally be passed back to the service that requested authentication. But as our services support working with sensitive data, you will also be required to use multi-factor authentication (somewhat simplified that means just knowing a password should not be enough, typically something more such as having a physical object should be required).</p> <p>With Life Science Login, this means you will be asked to provide a second factor before being able to advance to our services.</p> <p>If Life Science Login needs to do multifactor authentication by itself, you will be sent to the Life Science Login MFA site.</p> <p>For clarity; there's nothing wrong with using a hardware token (e.g. USB key) or other solution, but since the Time-based One-Time Password (TOTP) support is the common denominator, that's shown here.</p> <p>.</p> <p>Since Life Science Login tries to be useful, it supports using modern standards for authentication over the web. Unfortunately, that may mean you get different behaviours depending on what web browser you are using, whatever you have any helper extensions (e.g. password manager), if you have a USB-key connect and possibly even if you have a phone nearby.</p> <p>Since those behaviours differ so much, we won't show them.</p>"},{"location":"dsp/getting-started/life-science-login/#enrolling-a-new-token-for-multifactor-authentication","title":"Enrolling a new token for multifactor authentication","text":"<p>When arriving at the MFA site the first time, it will tell you who you are authenticated as in Life Science Login and inform you that you get in without additional credentials this time.</p> <p></p> <p>You will then be guided through the enrollment flow, starting with the ability to name your token.</p> <p></p> <p>Next, the flow tries to ensure you have a TOTP application available. It suggests alternatives for Android and iOS, but you don't need to use those applications as TOTP is a standard. The list of working apps include Twilio Authy, Google Authenticator, Microsoft Authenticator, FortiToken, Duo security authentication, common password managers and many more.</p> <p>If you do not already use two-factor authentication with an app, we strongly recommend choosing one that supports some kind of secure network synchronisation to handle cases where your device stops working (this should do encryption on device).</p> <p></p> <p>Once you have confirmed you have an app, it will show you a QR code for easy addition of the second factor. If you are using a phone, you should be able to scan that and hopefully have the account added automatically.</p> <p>If not, you can ask it to reveal the secret as text and add that to your MFA solution manually.</p> <p>Once you have added the account to your solution, it should present you with the current code (this will update regularly, at any time it is requested you should enter what is currently shown).</p> <p></p> <p>If that works, it will remember that you have registered the account on your side. It calls with that the \"token is enrolled\"</p> <p></p> <p>It will then let you know that multifactor authentication has been activated.</p> <p></p> <p>Next, it will inform you about backup codes (in case you loose your phone or similar). Even if you have a solution that helps with network backup, downloading backup codes and storing them securely is strongly recommended.</p> <p></p> <p>Once you've done that, MFA activation is complete.</p> <p></p>"},{"location":"dsp/getting-started/life-science-login/#attribute-release","title":"Attribute release","text":"<p>To operate our services, we need some additional details about you from Life Science Login. For them to be able to pass them to us, they need you to acknowledge that:</p> <p>Click \"Yes, continue\" to let Life Science Login give us those details. If you want to, you can choose \"Remember\" not to have to click through that screen the next time.</p> <p></p>"},{"location":"dsp/getting-started/life-science-login/#back-to-aida-data-hub-services","title":"Back to AIDA Data Hub services","text":"<p>Once you've registered and accepted that our services can get additional details, you should be redirected back to the service for which you originally initiated the log in. You will now be able to use the same Life Science login profile for all of the AIDA Data Hub services (as well as any other of the European research infrastructures using it).</p>"},{"location":"dsp/getting-started/vm-access/","title":"Setting up and logging into a machine in DSP","text":"<p>This guide assumes you have access to the Horizon interface, if not, see the first login guide.</p>"},{"location":"dsp/getting-started/vm-access/#some-terminology","title":"Some terminology","text":"<p>Some terms used in OpenStack may need some explanation:</p> <ul> <li>an instance means an actual virtual machine (VM), it can be turned off (in   state <code>shutdown</code>) or running, spawning and so on</li> <li>a flavor is a resource specification for a type of virtual machine, e.g.   say that a small machine can have 1 CPU core, 1 GByte of RAM and no disk)</li> <li>a volume is a virtual disk</li> <li>a security group is how OpenStack manages traffic filtering for a machine. In   OpenStack all traffic is disallowed unless there is a rule in a security group   attached to the machine specifying that the specific traffic is allowed. This   can be done with various filters (e.g. IP addresses, port, direction and so   on)</li> <li>ingress mean incoming</li> <li>egress mean outgoing</li> <li>a floating ip is a virtual IP address that can be assigned to a machine to   make it reachable at that address, but in contrast to \"regular\" addresses,   these will typically not show up on the machine and can also be removed and   reassigned at any time</li> <li>server groups is a way of grouping virtual machines together for purposes of   scheduling in openstack (\"affinity\"), it can be used to say that some virtual   machines should run on the same physical host (to offer higher bandwidth and   lower latency for things that talk to a lot) or on different physical hosts   to add fault-tolerance</li> </ul>"},{"location":"dsp/getting-started/vm-access/#pecularities-for-dsp","title":"Pecularities for DSP","text":"<p>Since DSP aims to support research on sensitive data, there a a few things that differ from what you'd normally encounter in a cloud setup.</p> <p>The most important is that there is no way to connect to virtual machines directly. It's quite common that virtual machines use internal networking and can be connected to the outside world by assigning an IP from a \"public\" network.</p> <p>This can be done within DSP as well, but the public network is completely internal to the DSP, so exposing a machine on the public network in DSP lets you connect to it through our gateway or from other DSP projects if your security groups allow it.</p>"},{"location":"dsp/getting-started/vm-access/#preparations","title":"Preparations","text":"<p>To be able to access any virtual machines you create, you will need to be able to authenticate to it. In practice, this means you should upload the public part of a SSH key pair so it can be preloaded on machines you create.</p> <p>This is accessible in Horizon under Compute \u082c Key Pairs where you can see your keys and import or create new ones.</p> <p></p> <p>On the key pairs screen, your known key pairs will be listed and you have buttons to create a new key pair (you probably don't want to use this), import a key and delete a key.</p> <p></p> <p>Click the \"Import Public Key\" to open the key importer.</p> <p></p> <p>Choose a name for your key, select the type (SSH Key) and either upload or copy paste the public part of your key pair (authentication depends on you proving you have the private part which can be verified by someone that has the public part).</p>"},{"location":"dsp/getting-started/vm-access/#creating-a-vm","title":"Creating a VM","text":"<p>Now, you can actually create a VM, go to the Instances screen (Compute \u082c Instances).</p> <p></p> <p>Similarly as for key pairs, you get to see a list of resources (instances) and have a few buttons for quick access.</p> <p></p> <p>Clicking the \"Launch Instance\" buttons brings up the instance launcher which will guide you through the instance creation. While it has a guided flow, you jump around as you please. You can see things you must take care of being marked with an asterisk (*) in the left pane.</p> <p>On the first screen, you enter a name and a description for your VM.</p> <p>Once done, advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>On the second screen, you need to choose what to start. The \"Select Boot Source\" lets you choose between Image (can be said to be a prepared VM), \"Instance Snapshot\" (a snapshot you've taken from a VM previously), \"Volume\" (a virtual disk) or \"Volume Snapshot\".</p> <p>Typically you will be using Image unless you have a special use case.</p> <p>To choose what to start from, click the up arrow button to the right in the list of available resources. We'll use the \"Ubuntu Noble server\" image for this demonstration.</p> <p>Once done, advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next, you'll need to choose the flavor to use. A flavor in OpenStack describes the resources (memory, cores, disk and such, GPUs) allocated to the VM. Same as for the Image, choosing one is done by using the arrow up button to the right in the list.</p> <p>Once this is done, you can normally start your VM by using \"Launch Instance\" at the lower right (it should activate once you choose a flavor), but for this guide we'll go through the other possible steps.</p> <p>If you choose Image or Instance snapshot as source, you have the option of creating a new volume (virtual disk) for it, and if so, what size it should have (if you need more than the default suggested by the image) and if it should be automatically deleted when you remove your virtual machine.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next up is the networks screen which allows e.g. choosing what virtual networks are connected if you have access to many. It's unlikely you will want to do anything there for now.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next up is the network ports screen which allows e.g. choosing what virtual network connectors that are used if you have access to many. You probably don't need to do anything here..</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Security groups determine what security groups are attached to the virtual machine. A machine can have any number of security groups attached, each attached will potentially allow additional traffic to/from the VM.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next up is the key pair screen which lets you choose which key pair to preload. Same as with other screens, you can select one by clicking the arrow up button.</p> <p>At most one can be selected at the same time.</p> <p>The selected key pair will be offered as information to the virtual machine, there's no guarantee it's used (e.g. an instance snapshot might not care about) it at all.</p> <p>For virtual machines images intended to be used to create virtual machines, this will typically be assigned to the default user for the image. For e.g. an Ubuntu image, it will be added to the <code>ubuntu</code> user.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>The technology used to offer the key pair chosen above can do a lot more - see the cloud-init documentation for more informtation.</p> <p>The Configuration screen allows you to provide more configuration. That can be used to e.g. pre-create some additional users, set a password, partition drives or other things.</p> <p>This is an advanced future that will not be used in this guide.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next up is the server group screen where you can decide which (if any) server groups a virtual machine should belong to. These will be used to decide how scheduling happens.</p> <p>This is an advanced future that will not be used in this guide.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Next up is the scheduler hints screen where you can provide hints for the scheduler.</p> <p>This is an advanced future that will not be used in this guide.</p> <p>Advance by clicking the \"Next\" button to the lower right.</p> <p></p> <p>Finally the metadata screen allows you assign metadata to the virtual machine, either from a list of preloaded suggestions or custom keys (once added to your virtual machine you can provide values).</p> <p>Since we've reached the end of the guided experience, we'll create our virtual machine by clicking \"Launch Instance\".</p> <p></p> <p>After a short while, you'll be taken back to the Instance view where after some time your new virtual machine should pop up in the list. It will go through various stages but unless there is an issue, it should end up in Power state \"Running\", meaning it's powered on.</p> <p>You have a button for quick actions to the right or you can click your machine to go into the details screen for it.</p> <p></p> <p>After clicking your virtual machine to see more details, you will be presented with a view with more information in various tab, e.g. an overview.</p> <p></p> <p>There is also a tab for the machine log that can be useful when troubleshooting.</p> <p></p> <p>And there is a console tab for emergency access to the \"graphical console\" of the virtual machine. This is not indented to be used for a virtual desktop but rather for emergency cases (e.g. while it was stopped you disconnected and deleted a volume that is no longer needed but is expected to be mounted at start).</p> <p>Since we're happy with the virtual machine, we click the actions menu button to the upper right to fold out the menu.</p> <p>Some operations that are considered especially dangerous is marked by using another text color (red instead of black here).</p> <p></p> <p>Since we want to reach our VM from the outside, we'll go ahead and click \"Associate floating IP\" from the list.</p> <p></p> <p>There will be a drop-down list of addresses to choose from at IP address. We pick one at random.</p> <p>Port to be associated will be filled in correctly for most cases, so we disregard that for now. and click \"Associate\".</p> <p></p> <p>Once we've chosen, the new address will be visible in the overview tab as well as in the virtual machine list on the main Instances screen.</p> <p>But before we're done, we also need to actually make the virtual machine accessible, this is done by adding security groups that allow the traffic we want.</p> <p>To do this, we use the actions drop-down menu to select \"Edit Security Groups\". Note that there is currently a bug in the graphical interface so that active groups aren't shown correctly, but that doesn't stop us here, for right now, let's add all groups.</p> <p>Once we're done, we chose \"Save\" to make the changes happen.</p> <p></p>"},{"location":"dsp/getting-started/vm-access/#connecting-to-the-virtual-machine","title":"Connecting to the virtual machine","text":"<p>Now, we can finally try to connect to our new virtual machine. To do so, we need to use the floating IP we associated with the machine earlier.</p> <p>In this case, it's <code>10.253.16.34</code>.</p> <p>Since it's the most common and versatile, we'll use the standard OpenSSH SSH client here, but similar functionality should be achievable with other clients.</p> <p>As quick a quick connection without doing any configuration, we can connect with</p> <pre><code>ssh -o \"ProxyJump your.email@example.com@dsp.aida.scilifelab.se\" ubuntu@10.253.16.34\n</code></pre> <p>where <code>your.email@example.com</code> is replaced by your actual email address used for DSP. There will be a lot of <code>@</code> characters on that line, but it's fine.</p> <p>Running that command will probably ask you to about the key the first time. It's a good habit to verify unknown keys, so we should do that. The key for DSP has fingerprint as below.</p> <pre><code>256 SHA256:vg/InkHbVMb3FEyouth7f+WLi1OtEKgOJ88q49fVmj0 dsp (ED25519)\n+--[ED25519 256]--+\n|             +o  |\n|         .  . .. |\n|          =.. .  |\n|         +.o o   |\n|      . S.. . o  |\n|     = O.. o . ..|\n|      &amp;o=.+ o .o |\n|   o o.Bo=.E..o .|\n|  ..+.+ o+.o++...|\n+----[SHA256]-----+\n</code></pre> <p>Once you've checked and approved the key (the ), you will be shown a banner with a link.</p> <p></p> <p>Clicking that link will prompt you to go through with authentication through Life Science Login. If you go through that, you should end up on a page with a short message:</p> <pre><code>You are now logged in as &lt;your.email@example.com&gt; and should be able to continue in your ssh session.\n</code></pre> <p>(where <code>your.email@example.com</code> should be your actual email used for DSP).</p> <p>Once you get that, you can go back to the terminal, pressing return there should advance and allow your SSH client to connect your actual virtual machine.</p> <p>But since it's a completely new machine, we don't have a way of verifying the public key for it, so we'll need to go by faith here.</p> <p>It'a also possible that you get problems here if you create, delete and create many virtual machines and reuse the floating IPs to connect to, in that case <code>ssh</code> will help by suggesting commands to clean up conflicting details from your files.</p> <p></p> <p>Accepting that public key will allow us to advance. Since we've given the virtual machine our public key already, it can authenticate us and let us in.</p> <p></p> <p>It is good practice to protect keys with a passphrase, but I didn't need to type any here. That's because I use an agent to help with the keys so that I can add them once at login by typing the passphrase and then don't need to type it anymore. This is available with the <code>ssh-agent</code> tool, but also built-in to many common desktop environments, you can try e.g. <code>ssh-add -L</code> to list identities your agent know of, and if that works (doesn't give an error message) you can add your identities by e.g. <code>ssh-add ~/.ssh/mykeyfile</code> to add a specific key or just <code>ssh-add</code> to go through the default key files OpenSSH will look for.</p>"},{"location":"dsp/getting-started/vm-access/#nicer-configuration","title":"Nicer configuration","text":"<p>While it works to do as above, it can be tiresome having to click links to connect. Fortunately, OpenSSH offers way to improve the experience.</p> <p>To get out of clicking the link, we can use something called <code>connection multiplexing</code> which allows SSH to use a single connection to many different things. This happens after authentication, so activating it for the gateway means we can use it to connect multiple times.</p> <p>Since this means authentication does not happen again, it's something to consider and necessitate some precautions such as automatic locking when idle and so on (but such precautions should typically be in place already if you work with sensitive data).</p> <p>The configuration below asks SSH that new connections should automatically set up multiplexing and hang around after use, but stop after one half hour. There are also other options for <code>ControlMaster</code>, allowing for requesting confirmation before using the multiplexing, see the manual page <code>ssh_config(5)</code>.</p> <pre><code>ControlMaster auto\nControlPersist 1800\nControlPath ~/.ssh/socket-%r@%h-%p\n</code></pre> <p>OpenSSH also allows us to define things so we don't need to type it so much.</p> <pre><code>Host dspgateway\n  Hostname dsp.aida.scilifelab.se\n  User your.email@example.com\n</code></pre> <p>(where <code>your.email@example.com</code> should be replaced by your actual email used for DSP.)</p> <p>And OpenSSH also offers the <code>ProxyJump</code> feature to automatically use tunneling through a host, we can set this up for our VMs as such</p> <pre><code>Host 10.253.16.*\n  ProxyJump dspgateway\n  User ubuntu\n</code></pre> <p>combining these, we can put it in a file (e.g. <code>~/.ssh/dsp_config</code>) and add an include statement for it in the main SSH configuration (<code>~/.ssh/config</code>) such as</p> <pre><code>Include dsp_config\n</code></pre> <p>with <code>dsp_config</code> consisting of</p> <pre><code>ControlMaster auto\nControlPersist 1800\nControlPath ~/.ssh/socket-%r@%h-%p\n\nHost dspgateway\n  Hostname dsp.aida.scilifelab.se\n  User your.email@example.com\n\nHost 10.253.16.*\n  ProxyJump dspgateway\n  User ubuntu\n</code></pre> <p>I can just use the IP directly:</p> <pre><code>$ ssh 10.253.16.34\nLast login: Wed Feb  5 11:24:49 2025 from 10.253.254.251\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\nubuntu@mytestmachine:~$\n</code></pre> <p>(notice that I get a different view here with no message-of-the-day because I'm already logged in.)</p>"}]}